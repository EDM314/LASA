{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:57:16.652532700Z",
     "start_time": "2023-12-05T01:57:16.632532400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from Util.path_config import *\n",
    "\n",
    "def get_grades_data(years,bins=[0, 0.3, 0.7, 1],labels=[0,1,2]):\n",
    "    grades_list = []\n",
    "    for year in years:\n",
    "        grades = pd.read_excel(\"./data/scores/{}_scores.xlsx\".format(year), header=[0, 1], index_col=0)['成绩']\n",
    "        grades['target'] = pd.qcut(grades['期末'], bins, labels=labels)\n",
    "        grades_list.append(grades['target'])\n",
    "    return grades_list\n",
    "class AllMethodResults():\n",
    "    def __init__(self, target_years):\n",
    "        self.results = {}\n",
    "\n",
    "        self.target_years = target_years\n",
    "\n",
    "        self.debug = 1\n",
    "\n",
    "    # 添加一个方法的结果\n",
    "    def add(self, method_name, results):\n",
    "        if self.debug == 0:\n",
    "\n",
    "            self.results[method_name] = results\n",
    "        else:\n",
    "            print(f\"Debug: {method_name}, {results}\")\n",
    "\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        # 创建一个DataFrame，行为方法名，列为年份\n",
    "        df = pd.DataFrame.from_dict(self.results, orient='index', columns=self.target_years)\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'method'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "focus_student = 0\n",
    "methods_results_dict=[]\n",
    "target_years=range(2017,2024)\n",
    "\n",
    "\n",
    "results_obj = AllMethodResults(target_years)\n",
    "results_obj.debug=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0\n",
      "2     0\n",
      "3     2\n",
      "4     2\n",
      "5     2\n",
      "     ..\n",
      "72    0\n",
      "73    1\n",
      "74    0\n",
      "75    2\n",
      "76    1\n",
      "Name: target, Length: 76, dtype: category\n",
      "Categories (3, int64): [0 < 1 < 2]\n"
     ]
    }
   ],
   "source": [
    "data_list = [pd.read_excel(\"./data/answers/{}_answers.xlsx\".format(i), header=[0, 1], index_col=0) for i in range(2016,2024)]\n",
    "labels_list = get_grades_data(range(2016,2024))\n",
    "print(labels_list[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:57:51.841087300Z",
     "start_time": "2023-12-05T01:57:50.170380900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LASA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## random init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8051948051948052, 0.7938931297709924, 0.8256880733944955, 0.8225806451612904, 0.6593406593406593, 0.7865853658536586, 0.810126582278481]\n",
      "[0.7402597402597403, 0.816793893129771, 0.8073394495412844, 0.8467741935483871, 0.7362637362637363, 0.8109756097560976, 0.7974683544303798]\n",
      "[0.7402597402597403, 0.7938931297709924, 0.8256880733944955, 0.8225806451612904, 0.6373626373626373, 0.8048780487804879, 0.7721518987341772]\n",
      "[0.7532467532467533, 0.8320610687022901, 0.8256880733944955, 0.8225806451612904, 0.6153846153846154, 0.7987804878048781, 0.7848101265822784]\n",
      "[0.7792207792207793, 0.8015267175572519, 0.8440366972477065, 0.8306451612903226, 0.6703296703296703, 0.7926829268292683, 0.7848101265822784]\n",
      "[0.7402597402597403, 0.8091603053435115, 0.7981651376146789, 0.7903225806451613, 0.6593406593406593, 0.7987804878048781, 0.7974683544303798]\n",
      "[0.7922077922077922, 0.8320610687022901, 0.8073394495412844, 0.8306451612903226, 0.6373626373626373, 0.7865853658536586, 0.7721518987341772]\n",
      "[0.7662337662337663, 0.816793893129771, 0.8256880733944955, 0.8225806451612904, 0.6483516483516484, 0.7926829268292683, 0.810126582278481]\n",
      "[0.7922077922077922, 0.8015267175572519, 0.7889908256880734, 0.8387096774193549, 0.6593406593406593, 0.774390243902439, 0.8227848101265823]\n",
      "[0.7922077922077922, 0.8244274809160306, 0.8256880733944955, 0.7983870967741935, 0.6813186813186813, 0.7987804878048781, 0.7721518987341772]\n",
      "[0.8181818181818182, 0.7938931297709924, 0.8256880733944955, 0.8145161290322581, 0.6813186813186813, 0.8048780487804879, 0.7974683544303798]\n",
      "[0.7922077922077922, 0.8015267175572519, 0.8165137614678899, 0.8225806451612904, 0.6703296703296703, 0.7987804878048781, 0.8227848101265823]\n",
      "[0.8051948051948052, 0.8091603053435115, 0.8256880733944955, 0.8225806451612904, 0.6373626373626373, 0.7865853658536586, 0.7848101265822784]\n",
      "[0.8051948051948052, 0.8549618320610687, 0.8073394495412844, 0.8225806451612904, 0.6593406593406593, 0.7987804878048781, 0.7848101265822784]\n",
      "[0.7922077922077922, 0.7786259541984732, 0.7981651376146789, 0.8064516129032258, 0.6593406593406593, 0.7926829268292683, 0.7848101265822784]\n",
      "mean_mean_result: 0.7826139520613672\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class MCMM():\n",
    "    def __init__(self, n_components, n_features, n_values,weights=None,probs=None):\n",
    "        self.n_components = n_components\n",
    "        self.n_features = n_features\n",
    "        self.n_values = n_values\n",
    "        self.tol=1e-4\n",
    "        # 初始化参数\n",
    "        if weights is None:\n",
    "            self.weights = np.ones(n_components) / n_components\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        if probs is None:\n",
    "            self.probs = np.random.dirichlet(np.ones(n_values), n_features * n_components).reshape(\n",
    "            (n_components, n_features, n_values))\n",
    "        else:\n",
    "            self.probs = probs\n",
    "        self.max_iter = 100\n",
    "\n",
    "    def log_likelihood(self,X,weights,probs):\n",
    "        log_likelihood = 0\n",
    "        for n in range(X.shape[0]):\n",
    "            temp = 0\n",
    "            for k in range(self.n_components):\n",
    "                temp += weights[k] * np.prod(np.prod(np.power(probs[k, :], X[n, :]), axis=1))\n",
    "            log_likelihood += np.log(temp)\n",
    "        return log_likelihood\n",
    "\n",
    "\n",
    "    def e_step(self,X,weights,probs):\n",
    "        responsibilities = np.zeros((X.shape[0], self.n_components))\n",
    "        for k in range(self.n_components):\n",
    "            responsibilities[:, k] = weights[k] * np.prod(np.prod(np.power(probs[k, :], X), axis=2),axis=1)\n",
    "        responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
    "        return responsibilities\n",
    "\n",
    "    def m_step(self,X,responsibilities,probs):\n",
    "        effective_counts = responsibilities.sum(axis=0)\n",
    "\n",
    "        weights = effective_counts / X.shape[0]\n",
    "\n",
    "        for k in range(self.n_components):\n",
    "            probs[k, :] = np.sum(responsibilities[:, k][:, np.newaxis,np.newaxis] * X, axis=0)\n",
    "            probs[k, :] /= effective_counts[k]\n",
    "        return weights,probs\n",
    "\n",
    "    def fit(self,X):\n",
    "        prev_ll=-np.inf\n",
    "        for it in range(self.max_iter):\n",
    "            responsibilities = self.e_step(X,self.weights,self.probs)\n",
    "            self.weights,self.probs = self.m_step(X,responsibilities,self.probs)\n",
    "            ll = self.log_likelihood(X,self.weights,self.probs)\n",
    "            if np.abs(ll-prev_ll)<self.tol:\n",
    "                break\n",
    "            prev_ll=ll\n",
    "\n",
    "        return self.weights,self.probs,ll\n",
    "\n",
    "    def predict(self,X):\n",
    "        responsibilities = self.e_step(X,self.weights,self.probs)\n",
    "        return responsibilities.argmax(axis=1)\n",
    "# Learning Ability Modeling\n",
    "class LAM():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self,X,n_components=3,weight=None,probs=None):\n",
    "        X_t = X.values.transpose()\n",
    "        n_rows, n_cols = X_t.shape\n",
    "        n_values = 3\n",
    "        one_hot_matrix = np.zeros((n_rows, n_cols, n_values))\n",
    "        one_hot_matrix[np.arange(n_rows)[:, None], np.arange(n_cols), X_t+1] = 1\n",
    "        n_features = n_cols\n",
    "        import copy\n",
    "        weight,probs = copy.deepcopy(weight),copy.deepcopy(probs)\n",
    "        mcmm = MCMM(n_components=n_components,n_features=n_features,n_values=n_values,weights=weight,probs=probs)\n",
    "        pi,theta,ll = mcmm.fit(one_hot_matrix)\n",
    "        sort_value = [theta[i,:,2].mean() for i in range(n_components)]\n",
    "        sort_index = np.argsort(sort_value)\n",
    "        theta = theta[sort_index]\n",
    "        theta = theta.transpose(1,0,2)\n",
    "        return pi,theta\n",
    "    \n",
    "# Learning Ability Adaptation\n",
    "class LAA():\n",
    "    def run(self,n_iters=1,focus_student = None,params=None):\n",
    "        def distribution_alignment(Xs, Xt):\n",
    "            cov_src = np.cov(Xs.T) + np.eye(Xs.shape[1])\n",
    "            cov_tar = np.cov(Xt.T) + np.eye(Xt.shape[1])\n",
    "            A_coral = np.dot(scipy.linalg.fractional_matrix_power(cov_src, -0.5),\n",
    "                             scipy.linalg.fractional_matrix_power(cov_tar, 0.5))\n",
    "            np.linalg.multi_dot([Xs, scipy.linalg.fractional_matrix_power(cov_src, -0.5), scipy.linalg.fractional_matrix_power(cov_tar, 0.5)])\n",
    "            Xs_new = np.real(np.dot(Xs, A_coral))\n",
    "            return Xs_new\n",
    "\n",
    "\n",
    "        results_list=[]\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            # learning ability modeling module\n",
    "\n",
    "            lam = LAM()\n",
    "\n",
    "            learning_ability_data_list= []\n",
    "            for i,data in enumerate(data_list):\n",
    "                if params is None:\n",
    "                    pi,learning_ability = lam.fit_transform(data,n_components=3)\n",
    "                else:\n",
    "                    pi,learning_ability = lam.fit_transform(data,n_components=3,weight=params[i][0],probs=params[i][1].transpose(1,0,2).reshape(3,-1,3))\n",
    "\n",
    "                learning_ability = learning_ability[:,:,:].reshape(learning_ability.shape[0],-1)\n",
    "                learning_ability_data_list.append(learning_ability)\n",
    "\n",
    "            standardized_learning_ability_data_list = []\n",
    "            for learning_ability in learning_ability_data_list:\n",
    "                standardized_learning_ability = StandardScaler().fit_transform(learning_ability)\n",
    "                standardized_learning_ability_data_list.append(standardized_learning_ability)\n",
    "\n",
    "           \n",
    "            adapted_learning_ability_data_list_source = [] \n",
    "            for t in range(len(standardized_learning_ability_data_list)):\n",
    "                temp = []\n",
    "                for s in range(len(standardized_learning_ability_data_list)):\n",
    "                    if s==t:\n",
    "                        temp.append(standardized_learning_ability_data_list[t])\n",
    "                    elif s<t:\n",
    "                        temp.append(distribution_alignment(standardized_learning_ability_data_list[s],standardized_learning_ability_data_list[t]))\n",
    "                        # temp.append(standardized_learning_ability_data_list[s])\n",
    "                    else:\n",
    "                        pass\n",
    "                adapted_learning_ability_data_list_source.append(temp)\n",
    "            results=[]\n",
    "            for year_target in range(2017,2024):\n",
    "                source_X = np.vstack(adapted_learning_ability_data_list_source[year_target-2016][:year_target-2016])\n",
    "                if focus_student is not None:\n",
    "                    source_Y = np.hstack(labels_list[:year_target-2016])==focus_student\n",
    "                else:\n",
    "                    source_Y = pd.concat(labels_list[:year_target-2016],axis=0)\n",
    "                # print(source_Y)\n",
    "                target_X = adapted_learning_ability_data_list_source[year_target-2016][year_target-2016]\n",
    "                if focus_student is not None:\n",
    "                    target_Y = labels_list[year_target-2016]==focus_student\n",
    "                else:\n",
    "                    target_Y = labels_list[year_target-2016]\n",
    "\n",
    "\n",
    "                SVC_model = SVC(**{'C': 1, 'kernel': 'linear'})\n",
    "\n",
    "                SVC_model.fit(source_X,source_Y)\n",
    "\n",
    "                target_pred = SVC_model.predict(target_X)\n",
    "                results.append(accuracy_score(target_Y,target_pred))\n",
    "            print(results)\n",
    "            results_list.append(results)\n",
    "        return results_list\n",
    "\n",
    "\n",
    "np.random.seed(56)\n",
    "\n",
    "laa = LAA()\n",
    "results_list=laa.run(n_iters=15,focus_student=focus_student,params=None)\n",
    "\n",
    "results = np.array(results_list)\n",
    "mean_result = np.mean(results_list, axis=0)\n",
    "print( \"mean_mean_result:\", np.mean(mean_result))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:58:17.537811100Z",
     "start_time": "2023-12-05T01:57:56.408436900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hierarchical init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8051948051948052, 0.7709923664122137, 0.8348623853211009, 0.8387096774193549, 0.7802197802197802, 0.823170731707317, 0.810126582278481]\n",
      "mean_mean_result: 0.809039475507579\n"
     ]
    }
   ],
   "source": [
    "laa = LAA()\n",
    "import pickle\n",
    "with open('initial_params.pkl','rb') as f:\n",
    "    params = pickle.load(f)\n",
    "results_list=laa.run(n_iters=1,focus_student=focus_student,params=params)\n",
    "\n",
    "results = np.array(results_list)\n",
    "mean_result = np.mean(results_list, axis=0)\n",
    "print( \"mean_mean_result:\", np.mean(mean_result))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:59:44.006070200Z",
     "start_time": "2023-12-05T01:59:43.194434300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
